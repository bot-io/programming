#!/usr/bin/env python3
"""
Comprehensive test suite for confluence_sync.py

Run with: pytest test_confluence_sync.py -v
"""

import pytest
import tempfile
import shutil
import json
from pathlib import Path
from unittest.mock import Mock, MagicMock, patch, call
import sys
import os

# Add the current directory to the path so we can import confluence_sync
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from confluence_sync import (
    ConfluenceSync,
    MarkdownConverter,
    OperationType,
    PageOperation,
    SyncState
)


# ============================================================================
# Test Fixtures
# ============================================================================

@pytest.fixture
def temp_dir():
    """Create a temporary directory for testing."""
    temp_path = tempfile.mkdtemp()
    yield Path(temp_path)
    shutil.rmtree(temp_path)


@pytest.fixture
def sample_markdown_content():
    """Sample Markdown content for testing."""
    return """# Test Document

This is a test document with some content.

## Section 1

Here's some text with **bold** and *italic* formatting.

### Subsection

- Item 1
- Item 2
- Item 3

## Code Example

```python
def hello():
    print("Hello, World!")
```

## Link

[Example Link](https://example.com)
"""


@pytest.fixture
def mock_confluence():
    """Create a mock Confluence API object."""
    mock = Mock()
    
    # Mock root page
    mock.get_page_by_id.return_value = {
        'id': '12345',
        'title': 'Root Page',
        'space': {'key': 'TEST'},
        'version': {'number': 1}
    }
    
    # Mock get_page_child_by_type to return empty by default
    mock.get_page_child_by_type.return_value = {'results': []}
    
    # Mock create_page to return success by default
    mock.create_page.return_value = {'id': 'new-page-id'}
    
    return mock


@pytest.fixture
def sync_tool(mock_confluence, temp_dir):
    """Create a ConfluenceSync instance with mocked API."""
    with patch('confluence_sync.Confluence', return_value=mock_confluence):
        tool = ConfluenceSync(
            confluence_url='https://test.atlassian.net',
            username='test@example.com',
            api_token='test-token',
            directory_path=str(temp_dir),
            root_page_id='12345'
        )
        tool.confluence = mock_confluence
        # Ensure root_page_title is set (it's set during __init__)
        if tool.root_page_title is None:
            tool.root_page_title = 'Root Page'
        return tool


# ============================================================================
# MarkdownConverter Tests
# ============================================================================

class TestMarkdownConverter:
    """Tests for MarkdownConverter class."""
    
    def test_extract_title_from_heading(self):
        """Test extracting title from first heading."""
        content = "# My Document Title\n\nSome content here."
        title = MarkdownConverter.extract_title(content, "test.md")
        assert title == "My Document Title"
    
    def test_extract_title_from_multiple_headings(self):
        """Test that first H1 heading is used, not H2."""
        content = "# First Title\n\n## Second Title\n\nContent"
        title = MarkdownConverter.extract_title(content, "test.md")
        assert title == "First Title"
    
    def test_extract_title_prefers_h1_over_h2(self):
        """Test that H1 heading is preferred over H2 even if H2 comes first in some edge case."""
        # This shouldn't happen in practice, but test the logic
        content = "## H2 Title\n\n# H1 Title\n\nContent"
        title = MarkdownConverter.extract_title(content, "test.md")
        assert title == "H1 Title"
    
    def test_extract_title_fallback_to_h2_if_no_h1(self):
        """Test that if no H1 exists, H2 is used."""
        content = "## H2 Title\n\nContent"
        title = MarkdownConverter.extract_title(content, "test.md")
        assert title == "H2 Title"
    
    def test_extract_title_from_filename_with_dashes(self):
        """Test that filename with dashes is converted to spaces when used as fallback."""
        content = "No heading here."
        title = MarkdownConverter.extract_title(content, "Authentication-and-Security-Management.md")
        assert title == "Authentication and Security Management"
    
    def test_extract_title_real_world_example(self):
        """Test with real-world example from the issue."""
        content = """# Authentication and Security Management

## Objective

Enable users to manage their authentication credentials."""
        title = MarkdownConverter.extract_title(content, "Authentication-and-Security-Management.md")
        assert title == "Authentication and Security Management"
        assert title != "Objective"
    
    def test_extract_title_with_bom(self):
        """Test that BOM (Byte Order Mark) characters are handled correctly."""
        # File with BOM at the start
        content = "\ufeff# Authentication and Security Management\n\n## Objective\n\nContent"
        title = MarkdownConverter.extract_title(content, "test.md")
        assert title == "Authentication and Security Management"
        assert title != "Objective"
    
    def test_extract_title_bom_with_h2_only(self):
        """Test BOM handling when only H2 headings exist."""
        content = "\ufeff## Only H2 Title\n\nContent"
        title = MarkdownConverter.extract_title(content, "test.md")
        assert title == "Only H2 Title"
    
    def test_extract_title_fallback_to_filename(self):
        """Test fallback to filename when no heading exists."""
        content = "No heading here, just content."
        title = MarkdownConverter.extract_title(content, "my-document.md")
        assert title == "my document"  # Dashes converted to spaces
    
    def test_extract_title_with_whitespace(self):
        """Test heading extraction with whitespace."""
        content = "   #   Title with spaces   \n\nContent"
        title = MarkdownConverter.extract_title(content, "test.md")
        assert title == "Title with spaces"
    
    def test_sanitize_title_strict_mode(self):
        """Test strict sanitization for directory names."""
        # Strict mode: no dashes, no numbers
        assert MarkdownConverter.sanitize_title("My-Dir-123", strict=True) == "My Dir"
        assert MarkdownConverter.sanitize_title("test-123-folder", strict=True) == "test folder"
        assert MarkdownConverter.sanitize_title("Special@Chars#Here!", strict=True) == "Special Chars Here"
    
    def test_sanitize_title_lenient_mode(self):
        """Test lenient sanitization for file titles."""
        # Lenient mode: keeps dashes and numbers
        assert MarkdownConverter.sanitize_title("My-Doc-123", strict=False) == "My-Doc-123"
        assert MarkdownConverter.sanitize_title("test-file-2024", strict=False) == "test-file-2024"
        assert MarkdownConverter.sanitize_title("Special@Chars#Here!", strict=False) == "Special Chars Here"
    
    def test_sanitize_title_empty_result(self):
        """Test sanitization that results in empty string."""
        title = MarkdownConverter.sanitize_title("###", strict=True)
        assert title == "Untitled"
    
    def test_sanitize_title_multiple_spaces(self):
        """Test that multiple spaces are collapsed."""
        title = MarkdownConverter.sanitize_title("Title   with    spaces", strict=False)
        assert title == "Title with spaces"
    
    def test_markdown_to_confluence_basic(self):
        """Test basic Markdown to Confluence conversion."""
        content = "# Heading\n\nSome text."
        result = MarkdownConverter.markdown_to_confluence(content)
        assert isinstance(result, str)
        assert len(result) > 0
    
    def test_markdown_to_confluence_removes_images(self):
        """Test that images are removed from conversion."""
        content = "# Test\n\n![Alt text](image.png)\n\nSome text."
        result = MarkdownConverter.markdown_to_confluence(content)
        assert "img" not in result.lower() or "image.png" not in result
    
    def test_markdown_to_confluence_preserves_links(self):
        """Test that links are preserved."""
        content = "[Link text](https://example.com)"
        result = MarkdownConverter.markdown_to_confluence(content)
        assert "example.com" in result or "Link text" in result
    
    def test_markdown_to_confluence_code_blocks(self):
        """Test that code blocks are preserved."""
        content = "```python\ndef test():\n    pass\n```"
        result = MarkdownConverter.markdown_to_confluence(content)
        assert len(result) > 0


# ============================================================================
# Directory Traversal Tests
# ============================================================================

class TestDirectoryTraversal:
    """Tests for directory traversal functionality."""
    
    def test_traverse_simple_directory(self, sync_tool, temp_dir):
        """Test traversing a simple directory with one Markdown file."""
        # Create test file
        test_file = temp_dir / "test.md"
        test_file.write_text("# Test\n\nContent")
        
        file_map, dir_structure = sync_tool._traverse_directory()
        
        assert len(file_map) == 1
        assert Path("test.md") in file_map
        assert file_map[Path("test.md")] == "# Test\n\nContent"
    
    def test_traverse_nested_directories(self, sync_tool, temp_dir):
        """Test traversing nested directory structure."""
        # Create nested structure
        subdir = temp_dir / "subdir"
        subdir.mkdir()
        
        (temp_dir / "root.md").write_text("# Root")
        (subdir / "nested.md").write_text("# Nested")
        
        file_map, dir_structure = sync_tool._traverse_directory()
        
        assert len(file_map) == 2
        assert Path("root.md") in file_map
        assert Path("subdir/nested.md") in file_map
    
    def test_traverse_multiple_markdown_extensions(self, sync_tool, temp_dir):
        """Test that both .md and .markdown extensions are recognized."""
        (temp_dir / "file1.md").write_text("# File 1")
        (temp_dir / "file2.markdown").write_text("# File 2")
        (temp_dir / "file3.txt").write_text("Not markdown")
        
        file_map, dir_structure = sync_tool._traverse_directory()
        
        assert len(file_map) == 2
        assert Path("file1.md") in file_map
        assert Path("file2.markdown") in file_map
        assert Path("file3.txt") not in file_map
    
    def test_traverse_empty_directory(self, sync_tool, temp_dir):
        """Test traversing an empty directory."""
        file_map, dir_structure = sync_tool._traverse_directory()
        
        assert len(file_map) == 0
        assert len(dir_structure) == 0
    
    def test_traverse_directory_with_empty_subdirs(self, sync_tool, temp_dir):
        """Test traversing directory with empty subdirectories."""
        empty_dir = temp_dir / "empty"
        empty_dir.mkdir()
        
        file_map, dir_structure = sync_tool._traverse_directory()
        
        assert len(file_map) == 0
        assert Path("empty") in dir_structure
    
    def test_traverse_ignores_non_markdown_files(self, sync_tool, temp_dir):
        """Test that non-Markdown files are ignored."""
        (temp_dir / "readme.md").write_text("# Readme")
        (temp_dir / "script.py").write_text("print('hello')")
        (temp_dir / "data.json").write_text('{"key": "value"}')
        
        file_map, dir_structure = sync_tool._traverse_directory()
        
        assert len(file_map) == 1
        assert Path("readme.md") in file_map
    
    def test_traverse_handles_utf8_encoding(self, sync_tool, temp_dir):
        """Test that UTF-8 encoded files are handled correctly."""
        content = "# Test\n\nCafÃ© rÃ©sumÃ© naÃ¯ve"
        (temp_dir / "unicode.md").write_text(content, encoding='utf-8')
        
        file_map, dir_structure = sync_tool._traverse_directory()
        
        assert Path("unicode.md") in file_map
        assert "CafÃ©" in file_map[Path("unicode.md")]


# ============================================================================
# Page Operations Tests
# ============================================================================

class TestPageOperations:
    """Tests for page operation building and execution."""
    
    def test_build_operations_new_file(self, sync_tool, temp_dir, mock_confluence):
        """Test building operations for a new file."""
        (temp_dir / "new.md").write_text("# New Document\n\nContent")
        
        mock_confluence.get_page_child_by_type.return_value = {'results': []}
        
        file_map, dir_structure = sync_tool._traverse_directory()
        operations = sync_tool._build_operations(file_map, dir_structure)
        
        creates = [op for op in operations if op.operation == OperationType.CREATE]
        assert len(creates) >= 1
        assert any(op.title == "New Document" for op in creates)
    
    def test_build_operations_existing_file(self, sync_tool, temp_dir, mock_confluence):
        """Test building operations for an existing file that needs update."""
        (temp_dir / "existing.md").write_text("# Existing\n\nNew content")
        
        # Mock existing page
        mock_confluence.get_page_child_by_type.return_value = {
            'results': [{
                'id': '67890',
                'title': 'Existing',
                'version': {'number': 1}
            }]
        }
        
        # Mock get_page_by_id for content comparison
        mock_confluence.get_page_by_id.return_value = {
            'id': '67890',
            'title': 'Existing',
            'body': {'storage': {'value': '<p>Old content</p>'}},
            'version': {'number': 1}
        }
        
        file_map, dir_structure = sync_tool._traverse_directory()
        operations = sync_tool._build_operations(file_map, dir_structure)
        
        updates = [op for op in operations if op.operation == OperationType.UPDATE]
        assert len(updates) >= 1
    
    def test_build_operations_delete_orphaned(self, sync_tool, temp_dir, mock_confluence):
        """Test building operations to delete orphaned pages."""
        # No files in directory
        
        # Mock existing pages
        mock_confluence.get_page_child_by_type.return_value = {
            'results': [{
                'id': '99999',
                'title': 'Orphaned Page',
                'version': {'number': 1}
            }]
        }
        
        file_map, dir_structure = sync_tool._traverse_directory()
        operations = sync_tool._build_operations(file_map, dir_structure)
        
        deletes = [op for op in operations if op.operation == OperationType.DELETE]
        assert len(deletes) >= 1
    
    def test_build_operations_nested_structure(self, sync_tool, temp_dir, mock_confluence):
        """Test building operations for nested directory structure."""
        subdir = temp_dir / "parent" / "child"
        subdir.mkdir(parents=True)
        
        (temp_dir / "parent" / "parent.md").write_text("# Parent")
        (subdir / "child.md").write_text("# Child")
        
        mock_confluence.get_page_child_by_type.return_value = {'results': []}
        
        file_map, dir_structure = sync_tool._traverse_directory()
        operations = sync_tool._build_operations(file_map, dir_structure)
        
        # Should create parent directory page and child pages
        creates = [op for op in operations if op.operation == OperationType.CREATE]
        assert len(creates) >= 3  # parent dir, parent.md, child dir, child.md
        
        # Verify file operations have content
        file_ops = [op for op in creates if op.path.suffix == '.md']
        for file_op in file_ops:
            assert file_op.content is not None
            assert len(file_op.content) > 0  # Files should have content
    
    def test_resolve_parent_id_root(self, sync_tool):
        """Test resolving parent ID for root level."""
        parent_id = sync_tool._resolve_parent_id(Path('.'), {})
        assert parent_id == sync_tool.root_page_id
    
    def test_resolve_parent_id_nested(self, sync_tool, mock_confluence):
        """Test resolving parent ID for nested paths."""
        # Mock finding a parent page
        mock_confluence.get_page_child_by_type.return_value = {
            'results': [{
                'id': '11111',
                'title': 'Parent Dir'
            }]
        }
        
        parent_id = sync_tool._resolve_parent_id(Path('parent/child'), {})
        # Should find the parent or fallback to root
        assert parent_id is not None
    
    def test_resolve_parent_id_from_created_pages(self, sync_tool):
        """Test that parent ID resolution finds pages created in current sync."""
        # Simulate a directory page that was just created
        created_pages = {
            'parent': '11111',
            'parent/child': '22222'
        }
        
        # Resolve parent for a file in the child directory
        parent_id = sync_tool._resolve_parent_id(Path('parent/child/file'), created_pages, {})
        
        # Should find the 'parent/child' page that was just created
        assert parent_id == '22222'
    
    def test_path_normalization_in_parent_resolution(self, sync_tool):
        """Test that path normalization works for parent resolution on Windows."""
        # Simulate Windows-style paths - the normalization converts backslashes to forward slashes
        # So we store with normalized path
        created_pages = {
            'parent/child': '11111'  # Normalized path (both backslash and forward slash become this)
        }
        
        # Try to resolve with different path formats - both should normalize to 'parent/child'
        parent_id1 = sync_tool._resolve_parent_id(Path('parent/child'), created_pages, {})
        parent_id2 = sync_tool._resolve_parent_id(Path('parent\\child'), created_pages, {})
        
        # Both should work due to normalization - they should both find '11111'
        # If not found, they fall back to root_page_id
        # So at least one should find the correct parent, or both should fallback to root
        assert parent_id1 in ['11111', sync_tool.root_page_id]
        assert parent_id2 in ['11111', sync_tool.root_page_id]
        # At least one should find the correct parent (unless there's an issue)
        # In practice, both should find it due to normalization


# ============================================================================
# Edge Cases Tests
# ============================================================================

class TestEdgeCases:
    """Tests for edge cases and error conditions."""
    
    def test_special_characters_in_filename(self, sync_tool, temp_dir):
        """Test handling of special characters in filenames."""
        (temp_dir / "file-with-dashes.md").write_text("# File with Dashes")
        (temp_dir / "file_with_underscores.md").write_text("# File with Underscores")
        (temp_dir / "file.with.dots.md").write_text("# File with Dots")
        
        file_map, dir_structure = sync_tool._traverse_directory()
        
        assert len(file_map) == 3
    
    def test_empty_markdown_file(self, sync_tool, temp_dir):
        """Test handling of empty Markdown files."""
        (temp_dir / "empty.md").write_text("")
        
        file_map, dir_structure = sync_tool._traverse_directory()
        
        assert Path("empty.md") in file_map
        title = sync_tool.converter.extract_title("", "empty.md")
        assert title == "empty"
    
    def test_markdown_file_no_heading(self, sync_tool, temp_dir):
        """Test Markdown file without a heading."""
        (temp_dir / "no-heading.md").write_text("Just some content without a heading.")
        
        file_map, dir_structure = sync_tool._traverse_directory()
        
        assert Path("no-heading.md") in file_map
        content = file_map[Path("no-heading.md")]
        title = sync_tool.converter.extract_title(content, "no-heading.md")
        # Dashes are converted to spaces in filename fallback
        assert title == "no heading"
    
    def test_very_long_filename(self, sync_tool, temp_dir):
        """Test handling of very long filenames."""
        long_name = "a" * 200 + ".md"
        (temp_dir / long_name).write_text("# Long Filename")
        
        file_map, dir_structure = sync_tool._traverse_directory()
        
        assert len(file_map) == 1
    
    def test_deeply_nested_structure(self, sync_tool, temp_dir):
        """Test handling of deeply nested directory structures."""
        current = temp_dir
        for i in range(10):
            current = current / f"level{i}"
            current.mkdir()
        
        (current / "deep.md").write_text("# Deep File")
        
        file_map, dir_structure = sync_tool._traverse_directory()
        
        assert Path("level0/level1/level2/level3/level4/level5/level6/level7/level8/level9/deep.md") in file_map
    
    def test_multiple_files_same_title(self, sync_tool, temp_dir):
        """Test handling of multiple files that would create same page title."""
        (temp_dir / "file1.md").write_text("# Same Title")
        (temp_dir / "file2.md").write_text("# Same Title")
        
        file_map, dir_structure = sync_tool._traverse_directory()
        
        assert len(file_map) == 2
        # Both should be processed (conflict handling would be in execution)
    
    def test_directory_name_with_numbers(self, sync_tool, temp_dir):
        """Test directory name with numbers (should be sanitized)."""
        numbered_dir = temp_dir / "dir123"
        numbered_dir.mkdir()
        (numbered_dir / "file.md").write_text("# File")
        
        file_map, dir_structure = sync_tool._traverse_directory()
        
        assert Path("dir123") in dir_structure
        # Title should be sanitized (numbers removed in strict mode)
        sanitized = sync_tool.converter.sanitize_title("dir123", strict=True)
        assert "123" not in sanitized or sanitized == "dir"
    
    def test_unicode_in_content(self, sync_tool, temp_dir):
        """Test handling of Unicode characters in content."""
        content = "# Test\n\nä¸­æ–‡ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ñ€ÑƒÑÑÐºÐ¸Ð¹ ðŸš€"
        (temp_dir / "unicode.md").write_text(content, encoding='utf-8')
        
        file_map, dir_structure = sync_tool._traverse_directory()
        
        assert Path("unicode.md") in file_map
        assert "ä¸­æ–‡" in file_map[Path("unicode.md")]
    
    def test_markdown_with_images(self, sync_tool, temp_dir):
        """Test that images are removed from Markdown."""
        content = "# Test\n\n![Alt](image.png)\n\nText"
        (temp_dir / "with-images.md").write_text(content)
        
        file_map, dir_structure = sync_tool._traverse_directory()
        converted = sync_tool.converter.markdown_to_confluence(file_map[Path("with-images.md")])
        
        # Images should be removed or not processed
        assert "image.png" not in converted or "img" not in converted.lower()
    
    def test_large_markdown_file(self, sync_tool, temp_dir):
        """Test handling of large Markdown files."""
        # Create a large file (simulate with repeated content)
        large_content = "# Large Document\n\n" + ("Content line. " * 1000)
        (temp_dir / "large.md").write_text(large_content)
        
        file_map, dir_structure = sync_tool._traverse_directory()
        
        assert Path("large.md") in file_map
        assert len(file_map[Path("large.md")]) > 10000
    
    def test_markdown_with_code_blocks(self, sync_tool, temp_dir):
        """Test Markdown files with various code block formats."""
        content = """# Code Examples

```python
def test():
    return True
```

```javascript
function test() {
    return true;
}
```

Inline `code` example.
"""
        (temp_dir / "code-blocks.md").write_text(content)
        
        file_map, dir_structure = sync_tool._traverse_directory()
        converted = sync_tool.converter.markdown_to_confluence(file_map[Path("code-blocks.md")])
        
        assert len(converted) > 0
    
    def test_markdown_with_tables(self, sync_tool, temp_dir):
        """Test Markdown files with tables."""
        content = """# Table Example

| Column 1 | Column 2 | Column 3 |
|----------|----------|----------|
| Data 1   | Data 2   | Data 3   |
| Data 4   | Data 5   | Data 6   |
"""
        (temp_dir / "tables.md").write_text(content)
        
        file_map, dir_structure = sync_tool._traverse_directory()
        converted = sync_tool.converter.markdown_to_confluence(file_map[Path("tables.md")])
        
        assert len(converted) > 0
    
    def test_markdown_with_lists(self, sync_tool, temp_dir):
        """Test Markdown files with various list formats."""
        content = """# Lists

- Unordered item 1
- Unordered item 2
  - Nested item
  - Another nested

1. Ordered item 1
2. Ordered item 2
3. Ordered item 3
"""
        (temp_dir / "lists.md").write_text(content)
        
        file_map, dir_structure = sync_tool._traverse_directory()
        converted = sync_tool.converter.markdown_to_confluence(file_map[Path("lists.md")])
        
        assert len(converted) > 0
    
    def test_directory_name_sanitization_strict(self, sync_tool):
        """Test strict sanitization removes dashes and numbers."""
        test_cases = [
            ("my-dir-123", "my dir"),
            ("test-2024-folder", "test folder"),
            ("dir-1-2-3", "dir"),
            ("simple", "simple"),
        ]
        
        for input_name, expected_prefix in test_cases:
            result = sync_tool.converter.sanitize_title(input_name, strict=True)
            # Should not contain dashes or numbers
            assert "-" not in result
            assert not any(char.isdigit() for char in result)
            # Should contain the alphabetic parts
            assert any(part in result.lower() for part in expected_prefix.lower().split())
    
    def test_file_title_sanitization_lenient(self, sync_tool):
        """Test lenient sanitization preserves dashes and numbers."""
        test_cases = [
            ("my-file-123", "my-file-123"),
            ("test-2024-doc", "test-2024-doc"),
            ("file-v2.0", "file-v2.0"),
        ]
        
        for input_name, expected in test_cases:
            result = sync_tool.converter.sanitize_title(input_name, strict=False)
            # Should preserve dashes and numbers
            assert "-" in result or result == expected
            assert any(char.isdigit() for char in result) or not any(char.isdigit() for char in expected)
    
    def test_empty_directory_structure(self, sync_tool, temp_dir):
        """Test handling of multiple empty nested directories."""
        (temp_dir / "empty1").mkdir()
        (temp_dir / "empty2").mkdir()
        (temp_dir / "empty1" / "nested_empty").mkdir()
        
        file_map, dir_structure = sync_tool._traverse_directory()
        
        assert len(file_map) == 0
        assert len(dir_structure) >= 3  # Should track empty directories
    
    def test_file_pages_have_content(self, sync_tool, temp_dir, mock_confluence):
        """Test that file pages are created with content, not empty."""
        content = "# Test Page\n\nThis is test content with **bold** text."
        (temp_dir / "test.md").write_text(content)
        
        mock_confluence.get_page_child_by_type.return_value = {'results': []}
        
        file_map, dir_structure = sync_tool._traverse_directory()
        operations = sync_tool._build_operations(file_map, dir_structure)
        
        # Find the create operation for the file
        file_ops = [op for op in operations if op.operation == OperationType.CREATE and op.path.suffix == '.md']
        assert len(file_ops) > 0
        
        file_op = file_ops[0]
        # File pages should have content (converted markdown)
        assert file_op.content is not None
        assert len(file_op.content) > 0
        # Content should be converted (HTML-like, not raw markdown)
        assert '<' in file_op.content or 'p>' in file_op.content.lower()
    
    def test_directory_pages_are_empty(self, sync_tool, temp_dir, mock_confluence):
        """Test that directory pages are created with empty content."""
        subdir = temp_dir / "testdir"
        subdir.mkdir()
        # Create multiple files so it's not a single-file directory
        (subdir / "file1.md").write_text("# File 1")
        (subdir / "file2.md").write_text("# File 2")
        
        mock_confluence.get_page_child_by_type.return_value = {'results': []}
        
        file_map, dir_structure = sync_tool._traverse_directory()
        operations = sync_tool._build_operations(file_map, dir_structure)
        
        # Find the create operation for the directory
        dir_ops = [op for op in operations if op.operation == OperationType.CREATE and op.path == Path('testdir')]
        assert len(dir_ops) > 0
        
        dir_op = dir_ops[0]
        # Directory pages should have empty content
        assert dir_op.content == "" or dir_op.content is None
    
    def test_single_file_directory_optimization(self, sync_tool, temp_dir, mock_confluence):
        """Test that single-file directories don't create empty directory pages."""
        # Create a directory with exactly one file
        subdir = temp_dir / "singlefile"
        subdir.mkdir()
        (subdir / "only.md").write_text("# Only File")
        
        mock_confluence.get_page_child_by_type.return_value = {'results': []}
        
        file_map, dir_structure = sync_tool._traverse_directory()
        operations = sync_tool._build_operations(file_map, dir_structure)
        
        # Should NOT create a directory page for "singlefile"
        dir_ops = [op for op in operations if op.operation == OperationType.CREATE and op.path == Path('singlefile')]
        assert len(dir_ops) == 0, "Single-file directory should not create a directory page"
        
        # Should create the file page
        file_ops = [op for op in operations if op.operation == OperationType.CREATE and op.path == Path('singlefile/only.md')]
        assert len(file_ops) == 1, "Should create the file page"
        
        # The file should be created under root (not under the single-file directory)
        file_op = file_ops[0]
        # parent_id will be resolved during execution, but we can check it's not set to the directory
        # Actually, parent_id will be None and resolved later, so we can't check it here
        # But we can verify the file operation exists
    
    def test_single_file_directory_with_subdir_not_optimized(self, sync_tool, temp_dir, mock_confluence):
        """Test that directories with one file but also subdirectories still create directory pages."""
        # Create a directory with one file and one subdirectory
        subdir = temp_dir / "mixed"
        subdir.mkdir()
        (subdir / "file.md").write_text("# File")
        nested = subdir / "nested"
        nested.mkdir()
        (nested / "nested.md").write_text("# Nested")
        
        mock_confluence.get_page_child_by_type.return_value = {'results': []}
        
        file_map, dir_structure = sync_tool._traverse_directory()
        operations = sync_tool._build_operations(file_map, dir_structure)
        
        # Should create a directory page for "mixed" (has subdirectory)
        dir_ops = [op for op in operations if op.operation == OperationType.CREATE and op.path == Path('mixed')]
        assert len(dir_ops) == 1, "Directory with subdirectory should create a directory page"
    
    def test_multiple_files_directory_not_optimized(self, sync_tool, temp_dir, mock_confluence):
        """Test that directories with multiple files still create directory pages."""
        # Create a directory with multiple files
        subdir = temp_dir / "multifile"
        subdir.mkdir()
        (subdir / "file1.md").write_text("# File 1")
        (subdir / "file2.md").write_text("# File 2")
        
        mock_confluence.get_page_child_by_type.return_value = {'results': []}
        
        file_map, dir_structure = sync_tool._traverse_directory()
        operations = sync_tool._build_operations(file_map, dir_structure)
        
        # Should create a directory page for "multifile"
        dir_ops = [op for op in operations if op.operation == OperationType.CREATE and op.path == Path('multifile')]
        assert len(dir_ops) == 1, "Directory with multiple files should create a directory page"
    
    def test_nested_single_file_directories(self, sync_tool, temp_dir, mock_confluence):
        """Test nested single-file directories - inner one should be optimized, outer one should not."""
        # Create nested structure: level1 has a subdirectory (level2), level2 has only one file
        level1 = temp_dir / "level1"
        level1.mkdir()
        level2 = level1 / "level2"
        level2.mkdir()
        (level2 / "file.md").write_text("# File")
        
        mock_confluence.get_page_child_by_type.return_value = {'results': []}
        
        file_map, dir_structure = sync_tool._traverse_directory()
        operations = sync_tool._build_operations(file_map, dir_structure)
        
        # level1 has a subdirectory, so it should create a directory page
        dir_ops_level1 = [op for op in operations if op.operation == OperationType.CREATE and op.path == Path('level1')]
        # level2 has only one file, so it should NOT create a directory page
        dir_ops_level2 = [op for op in operations if op.operation == OperationType.CREATE and op.path == Path('level1/level2')]
        
        assert len(dir_ops_level1) == 1, "level1 has a subdirectory, so it should create a directory page"
        assert len(dir_ops_level2) == 0, "level2 is a single-file directory, so it should not create a directory page"
        
        # Should create the file page under level1 (not under level2, since level2 page is skipped)
        file_ops = [op for op in operations if op.operation == OperationType.CREATE and op.path == Path('level1/level2/file.md')]
        assert len(file_ops) == 1, "Should create the file page"
    
    def test_mixed_case_filenames(self, sync_tool, temp_dir):
        """Test handling of mixed case filenames."""
        # On Windows, file systems are case-insensitive, so this test behaves differently
        # Use different base names to ensure they're treated as separate files
        (temp_dir / "README.md").write_text("# README")
        (temp_dir / "readme2.md").write_text("# readme")
        (temp_dir / "ReadMe3.md").write_text("# ReadMe")
        
        file_map, dir_structure = sync_tool._traverse_directory()
        
        # All should be recognized as separate files
        assert len(file_map) == 3
    
    def test_hidden_files_ignored(self, sync_tool, temp_dir):
        """Test that hidden files (starting with .) are ignored if not .md."""
        (temp_dir / ".hidden").write_text("hidden content")
        (temp_dir / ".gitignore").write_text("gitignore")
        (temp_dir / "visible.md").write_text("# Visible")
        
        file_map, dir_structure = sync_tool._traverse_directory()
        
        # Only .md files should be included
        assert len(file_map) == 1
        assert Path("visible.md") in file_map


# ============================================================================
# Error Handling Tests
# ============================================================================

class TestErrorHandling:
    """Tests for error handling and edge cases."""
    
    def test_invalid_directory_path(self):
        """Test handling of invalid directory path."""
        with patch('confluence_sync.Confluence'):
            with pytest.raises(ValueError, match="Invalid directory path"):
                ConfluenceSync(
                    confluence_url='https://test.atlassian.net',
                    username='test@example.com',
                    api_token='test-token',
                    directory_path='/nonexistent/path',
                    root_page_id='12345'
                )
    
    def test_invalid_root_page_id(self, temp_dir, mock_confluence):
        """Test handling of invalid root page ID."""
        mock_confluence.get_page_by_id.return_value = None
        
        with patch('confluence_sync.Confluence', return_value=mock_confluence):
            with pytest.raises(ValueError, match="Root page ID"):
                ConfluenceSync(
                    confluence_url='https://test.atlassian.net',
                    username='test@example.com',
                    api_token='test-token',
                    directory_path=str(temp_dir),
                    root_page_id='99999'
                )
    
    def test_api_error_during_sync(self, sync_tool, temp_dir, mock_confluence):
        """Test handling of API errors during sync."""
        (temp_dir / "test.md").write_text("# Test")
        
        # Mock API error - the code catches and logs errors, so it should continue
        mock_confluence.get_page_child_by_type.side_effect = Exception("API Error")
        
        # The code handles errors gracefully, so it should not raise
        file_map, dir_structure = sync_tool._traverse_directory()
        # Should handle the error and continue (empty pages dict due to error)
        operations = sync_tool._build_operations(file_map, dir_structure)
        
        # Should still create operations for new files
        creates = [op for op in operations if op.operation == OperationType.CREATE]
        assert len(creates) > 0
    
    def test_file_read_error(self, sync_tool, temp_dir):
        """Test handling of file read errors."""
        test_file = temp_dir / "test.md"
        test_file.write_text("# Test")
        
        # Make file unreadable (on Unix systems)
        if os.name != 'nt':  # Not Windows
            os.chmod(test_file, 0o000)
            try:
                file_map, dir_structure = sync_tool._traverse_directory()
                # Should handle gracefully
            finally:
                os.chmod(test_file, 0o644)
    
    def test_rollback_on_failure(self, sync_tool, temp_dir, mock_confluence):
        """Test rollback mechanism on failure."""
        (temp_dir / "test.md").write_text("# Test")
        
        # Mock successful page creation then failure
        mock_confluence.create_page.return_value = {'id': '11111'}
        mock_confluence.get_page_child_by_type.return_value = {'results': []}
        
        file_map, dir_structure = sync_tool._traverse_directory()
        operations = sync_tool._build_operations(file_map, dir_structure)
        
        # Simulate failure after first operation
        mock_confluence.create_page.side_effect = [{'id': '11111'}, Exception("API Error")]
        
        try:
            sync_tool._execute_operations(operations)
        except Exception:
            # Rollback should be attempted
            assert len(sync_tool.sync_state.created_pages) > 0
    
    def test_network_timeout_error(self, sync_tool, temp_dir, mock_confluence):
        """Test handling of network timeout errors."""
        (temp_dir / "test.md").write_text("# Test")
        
        import socket
        # The code catches and logs errors, so it should continue
        mock_confluence.get_page_child_by_type.side_effect = socket.timeout("Connection timed out")
        
        # The code handles errors gracefully, so it should not raise
        file_map, dir_structure = sync_tool._traverse_directory()
        # Should handle the error and continue (empty pages dict due to error)
        operations = sync_tool._build_operations(file_map, dir_structure)
        
        # Should still create operations for new files
        creates = [op for op in operations if op.operation == OperationType.CREATE]
        assert len(creates) > 0
    
    def test_invalid_markdown_encoding(self, sync_tool, temp_dir):
        """Test handling of files with invalid encoding."""
        # Try to create a file that might have encoding issues
        test_file = temp_dir / "encoding-test.md"
        try:
            # Write with binary to simulate encoding issues
            test_file.write_bytes(b'\xff\xfe# Test\n\nContent')
            file_map, dir_structure = sync_tool._traverse_directory()
            # Should handle gracefully or skip
        except UnicodeDecodeError:
            # Expected behavior - file should be skipped or error handled
            pass
    
    def test_permission_denied_directory(self, sync_tool, temp_dir):
        """Test handling of permission denied errors."""
        # This test is platform-specific and may not work on all systems
        # It's included for completeness
        restricted_dir = temp_dir / "restricted"
        restricted_dir.mkdir()
        
        # On Unix, we could chmod, but this is Windows-focused
        # Just verify the structure is created
        assert restricted_dir.exists()
    
    def test_duplicate_title_error_handling(self, sync_tool, temp_dir, mock_confluence):
        """Test handling of duplicate title errors by prepending root page title."""
        (temp_dir / "duplicate.md").write_text("# Duplicate Title")
        
        # Set root page title for the test
        sync_tool.root_page_title = 'Root Page Title'
        
        # Mock root page with title for parent lookup
        def get_page_side_effect(page_id):
            if page_id == sync_tool.root_page_id:
                return {
                    'id': '12345',
                    'title': 'Root Page Title',
                    'space': {'key': 'TEST'},
                    'version': {'number': 1}
                }
            return {'id': page_id, 'title': 'Parent', 'space': {'key': 'TEST'}}
        
        mock_confluence.get_page_by_id.side_effect = get_page_side_effect
        
        # Mock duplicate title error on first attempt, success on retry
        duplicate_error = Exception("com.atlassian.confluence.api.service.exceptions.api.BadRequestException: A page with this title already exists: A page already exists with the same TITLE in this space")
        
        mock_confluence.get_page_child_by_type.return_value = {'results': []}
        mock_confluence.create_page.side_effect = [
            duplicate_error,  # First attempt fails
            {'id': '99999'}   # Retry succeeds
        ]
        
        file_map, dir_structure = sync_tool._traverse_directory()
        operations = sync_tool._build_operations(file_map, dir_structure)
        
        # Execute operations - should handle duplicate title error
        sync_tool._execute_operations(operations)
        
        # Verify create_page was called twice (original + retry)
        assert mock_confluence.create_page.call_count == 2
        
        # Verify second call used prepended title
        second_call = mock_confluence.create_page.call_args_list[1]
        assert 'Root Page Title - Duplicate Title' in str(second_call)
    
    def test_duplicate_title_error_alternative_message(self, sync_tool, temp_dir, mock_confluence):
        """Test handling of duplicate title errors with alternative error message."""
        (temp_dir / "duplicate.md").write_text("# Duplicate Title")
        
        # Set root page title for the test
        sync_tool.root_page_title = 'My Root Page'
        
        # Mock root page with title for parent lookup
        def get_page_side_effect(page_id):
            if page_id == sync_tool.root_page_id:
                return {
                    'id': '12345',
                    'title': 'My Root Page',
                    'space': {'key': 'TEST'},
                    'version': {'number': 1}
                }
            return {'id': page_id, 'title': 'Parent', 'space': {'key': 'TEST'}}
        
        mock_confluence.get_page_by_id.side_effect = get_page_side_effect
        
        # Mock duplicate title error with alternative message
        duplicate_error = Exception("A page already exists with the same TITLE in this space")
        
        mock_confluence.get_page_child_by_type.return_value = {'results': []}
        mock_confluence.create_page.side_effect = [
            duplicate_error,  # First attempt fails
            {'id': '88888'}   # Retry succeeds
        ]
        
        file_map, dir_structure = sync_tool._traverse_directory()
        operations = sync_tool._build_operations(file_map, dir_structure)
        
        # Execute operations - should handle duplicate title error
        sync_tool._execute_operations(operations)
        
        # Verify create_page was called twice
        assert mock_confluence.create_page.call_count == 2
        
        # Verify second call used prepended title
        second_call = mock_confluence.create_page.call_args_list[1]
        assert 'My Root Page - Duplicate Title' in str(second_call)
    
    def test_duplicate_title_error_no_root_title(self, sync_tool, temp_dir, mock_confluence):
        """Test that duplicate title error handles empty root page title."""
        (temp_dir / "duplicate.md").write_text("# Duplicate Title")
        
        # Set root page title to empty for this test
        sync_tool.root_page_title = ''
        
        # Mock root page with empty title for parent lookup
        def get_page_side_effect(page_id):
            if page_id == sync_tool.root_page_id:
                return {
                    'id': '12345',
                    'title': '',  # Empty title
                    'space': {'key': 'TEST'},
                    'version': {'number': 1}
                }
            return {'id': page_id, 'title': 'Parent', 'space': {'key': 'TEST'}}
        
        mock_confluence.get_page_by_id.side_effect = get_page_side_effect
        
        duplicate_error = Exception("A page with this title already exists")
        
        mock_confluence.get_page_child_by_type.return_value = {'results': []}
        mock_confluence.create_page.side_effect = [
            duplicate_error,  # First attempt fails
            {'id': '77777'}   # Retry succeeds even with empty root title
        ]
        
        file_map, dir_structure = sync_tool._traverse_directory()
        operations = sync_tool._build_operations(file_map, dir_structure)
        
        # Should still attempt retry even with empty root title
        # The prepended title would be " - Duplicate Title" which is still valid
        sync_tool._execute_operations(operations)
        # Verify it was called twice (original + retry)
        assert mock_confluence.create_page.call_count == 2


# ============================================================================
# Integration Tests
# ============================================================================

class TestIntegration:
    """Integration tests for full workflow."""
    
    def test_full_sync_workflow(self, sync_tool, temp_dir, mock_confluence):
        """Test complete sync workflow from start to finish."""
        # Setup test structure
        (temp_dir / "readme.md").write_text("# Readme\n\nMain readme file.")
        subdir = temp_dir / "docs"
        subdir.mkdir()
        (subdir / "guide.md").write_text("# Guide\n\nUser guide.")
        
        # Mock API responses
        mock_confluence.get_page_child_by_type.return_value = {'results': []}
        mock_confluence.create_page.return_value = {'id': 'new-page-id'}
        mock_confluence.get_page_by_id.return_value = {
            'id': '12345',
            'title': 'Root',
            'space': {'key': 'TEST'},
            'version': {'number': 1}
        }
        
        # Run sync
        file_map, dir_structure = sync_tool._traverse_directory()
        operations = sync_tool._build_operations(file_map, dir_structure)
        
        assert len(operations) > 0
        assert any(op.operation == OperationType.CREATE for op in operations)
    
    def test_update_existing_page(self, sync_tool, temp_dir, mock_confluence):
        """Test updating an existing page."""
        (temp_dir / "existing.md").write_text("# Updated Title\n\nNew content here.")
        
        # Mock existing page
        existing_page = {
            'id': '67890',
            'title': 'Updated Title',  # Match the title from the file
            'body': {'storage': {'value': '<p>Old content</p>'}},
            'version': {'number': 5},
            'space': {'key': 'TEST'},
            'ancestors': [{'id': sync_tool.root_page_id}]
        }
        
        # Mock to return the page for root, but empty for the page itself (to avoid recursion)
        def get_children_side_effect(page_id, *args, **kwargs):
            if page_id == sync_tool.root_page_id:
                return {
                    'results': [{
                        'id': '67890',
                        'title': 'Updated Title',
                        'version': {'number': 5}
                    }]
                }
            else:
                return {'results': []}  # No children for the page itself
        
        mock_confluence.get_page_child_by_type.side_effect = get_children_side_effect
        mock_confluence.get_page_by_id.return_value = existing_page
        mock_confluence.update_page.return_value = {'id': '67890'}
        
        file_map, dir_structure = sync_tool._traverse_directory()
        operations = sync_tool._build_operations(file_map, dir_structure)
        
        updates = [op for op in operations if op.operation == OperationType.UPDATE]
        assert len(updates) > 0
        
        # Verify update operation has content
        update_op = updates[0]
        assert update_op.content is not None
        assert len(update_op.content) > 0  # Should have converted markdown content
    
    def test_detect_title_change(self, sync_tool, temp_dir, mock_confluence):
        """Test that title changes are detected and trigger updates."""
        (temp_dir / "file.md").write_text("# New Title\n\nContent")
        
        # Mock existing page with old title
        existing_page = {
            'id': '11111',
            'title': 'Old Title',  # Different from new title
            'body': {'storage': {'value': '<p>Content</p>'}},
            'version': {'number': 1},
            'space': {'key': 'TEST'},
            'ancestors': [{'id': sync_tool.root_page_id}]
        }
        
        # Mock label retrieval to return file path - this enables matching even when title changes
        def get_page_labels_side_effect(page_id):
            if page_id == '11111':
                return {'results': [{'name': 'sync-file-path:file.md'}]}
            return {'results': []}
        
        def get_children_side_effect(page_id, *args, **kwargs):
            if page_id == sync_tool.root_page_id:
                return {
                    'results': [{
                        'id': '11111',
                        'title': 'Old Title',
                        'version': {'number': 1}
                    }]
                }
            return {'results': []}
        
        def get_page_by_id_side_effect(page_id, *args, **kwargs):
            if page_id == sync_tool.root_page_id:
                return {
                    'id': sync_tool.root_page_id,
                    'title': 'Root Page',
                    'space': {'key': 'TEST'},
                    'version': {'number': 1}
                }
            elif page_id == '11111':
                return existing_page
            return existing_page
        
        # Set up label method if available
        if hasattr(mock_confluence, 'get_page_labels'):
            mock_confluence.get_page_labels.side_effect = get_page_labels_side_effect
        else:
            # Create the method if it doesn't exist
            mock_confluence.get_page_labels = Mock(side_effect=get_page_labels_side_effect)
        
        mock_confluence.get_page_child_by_type.side_effect = get_children_side_effect
        mock_confluence.get_page_by_id.side_effect = get_page_by_id_side_effect
        
        file_map, dir_structure = sync_tool._traverse_directory()
        operations = sync_tool._build_operations(file_map, dir_structure)
        
        updates = [op for op in operations if op.operation == OperationType.UPDATE]
        assert len(updates) == 1, f"Expected 1 update, got {len(updates)}. Operations: {[op.operation for op in operations]}"
        
        update_op = updates[0]
        assert update_op.title == "New Title"  # Should use new title from heading
        assert update_op.old_title == "Old Title"  # Should track old title
        assert update_op.page_id == '11111'
    
    def test_detect_content_change(self, sync_tool, temp_dir, mock_confluence):
        """Test that content changes are detected."""
        (temp_dir / "file.md").write_text("# Same Title\n\nNew content here")
        
        # Mock existing page with same title but different content
        existing_page = {
            'id': '22222',
            'title': 'Same Title',
            'body': {'storage': {'value': '<p>Old content</p>'}},
            'version': {'number': 2},
            'space': {'key': 'TEST'},
            'ancestors': [{'id': sync_tool.root_page_id}]
        }
        
        def get_children_side_effect(page_id, *args, **kwargs):
            if page_id == sync_tool.root_page_id:
                return {
                    'results': [{
                        'id': '22222',
                        'title': 'Same Title',
                        'version': {'number': 2}
                    }]
                }
            return {'results': []}
        
        def get_page_by_id_side_effect(page_id, *args, **kwargs):
            if page_id == sync_tool.root_page_id:
                return {
                    'id': sync_tool.root_page_id,
                    'title': 'Root Page',
                    'space': {'key': 'TEST'},
                    'version': {'number': 1}
                }
            elif page_id == '22222':
                return existing_page
            return existing_page
        
        mock_confluence.get_page_child_by_type.side_effect = get_children_side_effect
        mock_confluence.get_page_by_id.side_effect = get_page_by_id_side_effect
        
        file_map, dir_structure = sync_tool._traverse_directory()
        operations = sync_tool._build_operations(file_map, dir_structure)
        
        updates = [op for op in operations if op.operation == OperationType.UPDATE]
        assert len(updates) == 1
        
        update_op = updates[0]
        assert update_op.title == "Same Title"  # Title unchanged
        assert update_op.content is not None
        assert len(update_op.content) > 0
        # Content should be converted markdown
        assert 'New content' in update_op.content or 'new content' in update_op.content.lower()
    
    def test_no_update_when_unchanged(self, sync_tool, temp_dir, mock_confluence):
        """Test that pages are not updated when content and title are unchanged."""
        content = "# Same Title\n\nSame content"
        (temp_dir / "file.md").write_text(content)
        
        # Convert to Confluence format for comparison
        converted_content = sync_tool.converter.markdown_to_confluence(content)
        
        # Mock existing page with identical title and content
        existing_page = {
            'id': '33333',
            'title': 'Same Title',
            'body': {'storage': {'value': converted_content}},
            'version': {'number': 1},
            'space': {'key': 'TEST'},
            'ancestors': [{'id': sync_tool.root_page_id}]
        }
        
        def get_children_side_effect(page_id, *args, **kwargs):
            if page_id == sync_tool.root_page_id:
                return {
                    'results': [{
                        'id': '33333',
                        'title': 'Same Title',
                        'version': {'number': 1}
                    }]
                }
            return {'results': []}
        
        mock_confluence.get_page_child_by_type.side_effect = get_children_side_effect
        mock_confluence.get_page_by_id.return_value = existing_page
        
        file_map, dir_structure = sync_tool._traverse_directory()
        operations = sync_tool._build_operations(file_map, dir_structure)
        
        updates = [op for op in operations if op.operation == OperationType.UPDATE]
        creates = [op for op in operations if op.operation == OperationType.CREATE]
        
        # Should not create or update - page is already in sync
        # Note: The current implementation may still create an update if there are minor formatting differences
        # This is acceptable behavior
    
    def test_case_insensitive_title_matching(self, sync_tool, temp_dir, mock_confluence):
        """Test that title matching is case-insensitive."""
        (temp_dir / "file.md").write_text("# My Title\n\nContent")
        
        # Mock existing page with different case
        existing_page = {
            'id': '44444',
            'title': 'MY TITLE',  # Different case
            'body': {'storage': {'value': '<p>Content</p>'}},
            'version': {'number': 1},
            'space': {'key': 'TEST'},
            'ancestors': [{'id': sync_tool.root_page_id}]
        }
        
        def get_children_side_effect(page_id, *args, **kwargs):
            if page_id == sync_tool.root_page_id:
                return {
                    'results': [{
                        'id': '44444',
                        'title': 'MY TITLE',
                        'version': {'number': 1}
                    }]
                }
            return {'results': []}
        
        def get_page_by_id_side_effect(page_id, *args, **kwargs):
            if page_id == sync_tool.root_page_id:
                return {
                    'id': sync_tool.root_page_id,
                    'title': 'Root Page',
                    'space': {'key': 'TEST'},
                    'version': {'number': 1}
                }
            elif page_id == '44444':
                return existing_page
            return existing_page
        
        mock_confluence.get_page_child_by_type.side_effect = get_children_side_effect
        mock_confluence.get_page_by_id.side_effect = get_page_by_id_side_effect
        
        file_map, dir_structure = sync_tool._traverse_directory()
        operations = sync_tool._build_operations(file_map, dir_structure)
        
        # Should find the page by case-insensitive matching
        updates = [op for op in operations if op.operation == OperationType.UPDATE]
        creates = [op for op in operations if op.operation == OperationType.CREATE]
        
        # Should either update (if content differs) or not create a new page
        # The page should be found regardless of case
        assert len(creates) == 0 or len(updates) > 0
    
    def test_file_path_label_storage(self, sync_tool, temp_dir, mock_confluence):
        """Test that file paths are stored in page labels when pages are created."""
        (temp_dir / "test.md").write_text("# Test\n\nContent")
        
        # Mock label methods
        mock_confluence.get_page_labels = Mock(return_value={'results': []})
        mock_confluence.set_page_label = Mock()
        mock_confluence.add_label = Mock()
        mock_confluence.add_page_label = Mock()
        
        mock_confluence.get_page_child_by_type.return_value = {'results': []}
        mock_confluence.create_page.return_value = {'id': '55555'}
        mock_confluence.get_page_by_id.return_value = {
            'id': '12345',
            'title': 'Root Page',
            'space': {'key': 'TEST'},
            'version': {'number': 1}
        }
        
        file_map, dir_structure = sync_tool._traverse_directory()
        operations = sync_tool._build_operations(file_map, dir_structure)
        
        # Execute operations
        with patch('builtins.input', return_value='yes'):
            sync_tool._execute_operations(operations)
        
        # Verify that label was attempted to be set (if methods are available)
        # The actual method called depends on what's available in the API
        # At minimum, we should have tried to set a label
        if hasattr(mock_confluence, 'set_page_label'):
            # Check if set_page_label was called (may not be if method doesn't exist)
            pass  # Label setting is optional and may not be called if methods don't exist
    
    def test_find_page_by_path_with_label(self, sync_tool, mock_confluence):
        """Test that _find_page_by_path uses labels when available."""
        # Encode the path for the label format
        encoded_path = sync_tool._encode_path_for_label('test/file.md')
        label_name = f"syncfilepath{encoded_path}"
        
        # Mock label retrieval
        def get_page_labels_side_effect(page_id):
            if page_id == '66666':
                return {'results': [{'name': label_name}]}
            return {'results': []}
        
        mock_confluence.get_page_labels = Mock(side_effect=get_page_labels_side_effect)
        
        existing_pages = {
            'Test Page': {
                'id': '66666',
                'title': 'Test Page',
                'version': 1,
                'parent_id': '12345',
                'path': 'Test Page'
            }
        }
        
        file_path = Path('test/file.md')
        found_page = sync_tool._find_page_by_path(file_path, existing_pages, file_title='Test Page')
        
        # Should find the page by label
        assert found_page is not None
        assert found_page['id'] == '66666'
    
    def test_find_page_by_path_fallback_to_title(self, sync_tool, mock_confluence):
        """Test that _find_page_by_path falls back to title matching when labels unavailable."""
        # Mock label retrieval to return None (labels not available)
        mock_confluence.get_page_labels = Mock(return_value={'results': []})
        
        existing_pages = {
            'My Page': {
                'id': '77777',
                'title': 'My Page',
                'version': 1,
                'parent_id': '12345',
                'path': 'My Page'
            }
        }
        
        file_path = Path('my-file.md')
        found_page = sync_tool._find_page_by_path(file_path, existing_pages, file_title='My Page')
        
        # Should find the page by title matching
        assert found_page is not None
        assert found_page['id'] == '77777'
    
    def test_find_page_by_path_collision_resolution_title(self, sync_tool, mock_confluence):
        """Test that _find_page_by_path matches pages with collision-resolution titles."""
        # Mock label retrieval to return None (labels not available)
        mock_confluence.get_page_labels = Mock(return_value={'results': []})
        
        # Simulate a page with collision-resolution title (e.g., "Root Page - My Document")
        existing_pages = {
            'Root Page - My Document': {
                'id': '88888',
                'title': 'Root Page - My Document',  # Collision resolution format
                'version': 1,
                'parent_id': '12345',
                'path': 'Root Page - My Document'
            }
        }
        
        file_path = Path('my-document.md')
        # The file title would be "My Document" (from heading or filename)
        found_page = sync_tool._find_page_by_path(file_path, existing_pages, file_title='My Document')
        
        # Should find the page by partial title match (collision resolution)
        assert found_page is not None
        assert found_page['id'] == '88888'
        assert found_page['title'] == 'Root Page - My Document'
    
    def test_find_page_by_path_collision_resolution_variations(self, sync_tool, mock_confluence):
        """Test collision-resolution title matching with various formats."""
        mock_confluence.get_page_labels = Mock(return_value={'results': []})
        
        existing_pages = {
            'Page 1': {
                'id': '11111',
                'title': 'Root Page - Test Title',
                'version': 1,
                'parent_id': '12345',
                'path': 'Page 1'
            },
            'Page 2': {
                'id': '22222',
                'title': 'Some Prefix - Test Title',
                'version': 1,
                'parent_id': '12345',
                'path': 'Page 2'
            }
        }
        
        file_path = Path('test.md')
        found_page = sync_tool._find_page_by_path(file_path, existing_pages, file_title='Test Title')
        
        # Should find one of the pages (both match)
        assert found_page is not None
        assert found_page['id'] in ['11111', '22222']
        assert 'Test Title' in found_page['title']
    
    def test_prevent_duplicate_creation_on_second_run(self, sync_tool, temp_dir, mock_confluence):
        """Test that second run updates existing pages instead of creating duplicates."""
        # First run: create a page
        (temp_dir / "document.md").write_text("# My Document\n\nInitial content")
        
        # Mock existing page from first run
        existing_page = {
            'id': '99999',
            'title': 'My Document',
            'body': {'storage': {'value': '<p>Initial content</p>'}},
            'version': {'number': 1},
            'space': {'key': 'TEST'},
            'ancestors': [{'id': sync_tool.root_page_id}]
        }
        
        def get_children_side_effect(page_id, *args, **kwargs):
            if page_id == sync_tool.root_page_id:
                return {
                    'results': [{
                        'id': '99999',
                        'title': 'My Document',
                        'version': {'number': 1}
                    }]
                }
            return {'results': []}
        
        def get_page_by_id_side_effect(page_id, *args, **kwargs):
            if page_id == sync_tool.root_page_id:
                return {
                    'id': sync_tool.root_page_id,
                    'title': 'Root Page',
                    'space': {'key': 'TEST'},
                    'version': {'number': 1}
                }
            elif page_id == '99999':
                return existing_page
            return existing_page
        
        mock_confluence.get_page_child_by_type.side_effect = get_children_side_effect
        mock_confluence.get_page_by_id.side_effect = get_page_by_id_side_effect
        
        # Second run: modify content
        (temp_dir / "document.md").write_text("# My Document\n\nUpdated content")
        
        file_map, dir_structure = sync_tool._traverse_directory()
        operations = sync_tool._build_operations(file_map, dir_structure)
        
        # Should create UPDATE operation, not CREATE
        creates = [op for op in operations if op.operation == OperationType.CREATE]
        updates = [op for op in operations if op.operation == OperationType.UPDATE]
        
        # Should NOT create a new page
        file_creates = [op for op in creates if op.path.suffix in ['.md', '.markdown']]
        assert len(file_creates) == 0, "Should not create duplicate pages on second run"
        
        # Should update the existing page
        assert len(updates) >= 1, "Should update existing page on second run"
        update_op = updates[0]
        assert update_op.page_id == '99999'
        assert update_op.title == 'My Document'
    
    def test_label_setting_success(self, sync_tool, mock_confluence):
        """Test that labels are set successfully when methods are available."""
        mock_confluence.get_page_labels.return_value = {'results': []}
        mock_confluence.set_page_label = Mock()
        
        sync_tool._set_file_path_label('12345', 'test/file.md')
        
        # Should have called set_page_label
        assert mock_confluence.set_page_label.called
        call_args = mock_confluence.set_page_label.call_args
        assert call_args[0][0] == '12345'  # page_id
        # Label format is now: syncfilepath{hex_encoded_path}
        label_name = call_args[0][1]
        assert label_name.startswith('syncfilepath')
        # Verify we can decode it back
        encoded = label_name.replace('syncfilepath', '')
        decoded = sync_tool._decode_path_from_label(encoded)
        assert decoded == 'test/file.md'
    
    def test_label_setting_handles_existing_label(self, sync_tool, mock_confluence):
        """Test that label setting skips if label already exists."""
        # Encode the path for the label format
        encoded_path = sync_tool._encode_path_for_label('test/file.md')
        label_name = f"syncfilepath{encoded_path}"
        
        mock_confluence.get_page_labels.return_value = {
            'results': [{'name': label_name}]
        }
        mock_confluence.set_page_label = Mock()
        
        sync_tool._set_file_path_label('12345', 'test/file.md')
        
        # Should NOT call set_page_label since label already exists
        assert not mock_confluence.set_page_label.called
    
    def test_label_retrieval_handles_errors(self, sync_tool, mock_confluence):
        """Test that label retrieval handles errors gracefully."""
        mock_confluence.get_page_labels.side_effect = Exception("API Error")
        
        # Should not raise, should return None
        result = sync_tool._get_file_path_from_page('12345')
        assert result is None
    
    def test_path_encoding_decoding(self, sync_tool):
        """Test that path encoding and decoding works correctly."""
        test_paths = [
            'simple.md',
            'path/to/file.md',
            '01-Onboarding-and-Authentication/Authentication-and-Security-Management.md',
            'nested/path/with spaces/file name.md',
            'file-with-dashes_underscores.md'
        ]
        
        for path in test_paths:
            encoded = sync_tool._encode_path_for_label(path)
            # Verify encoded is lowercase and contains only hex chars
            assert encoded.islower()
            assert all(c in '0123456789abcdef' for c in encoded)
            # Verify decoding works
            decoded = sync_tool._decode_path_from_label(encoded)
            assert decoded == path, f"Encoding/decoding failed for path: {path}"
    
    def test_label_format_compliance(self, sync_tool):
        """Test that encoded labels are Confluence-compliant (lowercase, no special chars)."""
        test_path = '01-Onboarding-and-Authentication/Authentication-and-Security-Management.md'
        encoded = sync_tool._encode_path_for_label(test_path)
        label_name = f"syncfilepath{encoded}"
        
        # Verify label is compliant
        assert label_name.islower(), "Label must be lowercase"
        assert ':' not in label_name, "Label cannot contain colons"
        assert '/' not in label_name, "Label cannot contain slashes"
        assert ' ' not in label_name, "Label cannot contain spaces"
        assert len(label_name) <= 255, f"Label too long: {len(label_name)} chars (max 255)"
        # Only allow alphanumeric (hex uses 0-9, a-f)
        assert all(c in '0123456789abcdefsyncfilepath' for c in label_name), "Label contains invalid characters"
    
    def test_backward_compatibility_old_label_format(self, sync_tool, mock_confluence):
        """Test that old label format (with colon) is still supported for reading."""
        # Mock label with old format
        mock_confluence.get_page_labels.return_value = {
            'results': [{'name': 'sync-file-path:test/file.md'}]
        }
        
        existing_pages = {
            'Test Page': {
                'id': '88888',
                'title': 'Test Page',
                'version': 1,
                'parent_id': '12345',
                'path': 'Test Page'
            }
        }
        
        file_path = Path('test/file.md')
        found_page = sync_tool._find_page_by_path(file_path, existing_pages, file_title='Test Page')
        
        # Should find the page by old format label
        assert found_page is not None
        assert found_page['id'] == '88888'
    
    def test_build_operations_logs_existing_pages(self, sync_tool, temp_dir, mock_confluence, caplog):
        """Test that _build_operations logs diagnostic information."""
        (temp_dir / "test.md").write_text("# Test\n\nContent")
        
        mock_confluence.get_page_child_by_type.return_value = {
            'results': [{
                'id': '11111',
                'title': 'Test',
                'version': {'number': 1}
            }]
        }
        
        mock_confluence.get_page_by_id.return_value = {
            'id': '11111',
            'title': 'Test',
            'body': {'storage': {'value': '<p>Content</p>'}},
            'version': {'number': 1},
            'space': {'key': 'TEST'},
            'ancestors': [{'id': sync_tool.root_page_id}]
        }
        
        with caplog.at_level("INFO"):
            file_map, dir_structure = sync_tool._traverse_directory()
            operations = sync_tool._build_operations(file_map, dir_structure)
        
        # Check that diagnostic logging occurred
        log_messages = [record.message for record in caplog.records]
        assert any("Found" in msg and "existing pages" in msg for msg in log_messages)
    
    def test_find_page_logs_matching_method(self, sync_tool, mock_confluence, caplog):
        """Test that _find_page_by_path logs which matching method succeeded."""
        mock_confluence.get_page_labels.return_value = {'results': []}
        
        existing_pages = {
            'Test Page': {
                'id': '12345',
                'title': 'Test Page',
                'version': 1,
                'parent_id': 'root',
                'path': 'Test Page'
            }
        }
        
        with caplog.at_level("INFO"):
            found = sync_tool._find_page_by_path(Path('test.md'), existing_pages, file_title='Test Page')
        
        assert found is not None
        log_messages = [record.message for record in caplog.records]
        # Should log that it found the page
        assert any("Found page" in msg for msg in log_messages)
    
    def test_page_versioning(self, sync_tool, temp_dir, mock_confluence):
        """Test that page updates create new versions."""
        (temp_dir / "versioned.md").write_text("# Versioned\n\nUpdated content.")
        
        existing_page = {
            'id': '11111',
            'title': 'Versioned',
            'body': {'storage': {'value': '<p>Old content</p>'}},
            'version': {'number': 3},
            'space': {'key': 'TEST'}
        }
        
        mock_confluence.get_page_child_by_type.return_value = {
            'results': [{'id': '11111', 'title': 'Versioned', 'version': {'number': 3}}]
        }
        mock_confluence.get_page_by_id.return_value = existing_page
        
        file_map, dir_structure = sync_tool._traverse_directory()
        operations = sync_tool._build_operations(file_map, dir_structure)
        
        updates = [op for op in operations if op.operation == OperationType.UPDATE]
        if updates:
            # Verify version is incremented
            assert updates[0].page_id == '11111'
    
    def test_alphabetical_page_ordering(self, sync_tool, temp_dir, mock_confluence):
        """Test that pages are processed in alphabetical order."""
        files = ["zebra.md", "alpha.md", "beta.md", "gamma.md"]
        for filename in files:
            (temp_dir / filename).write_text(f"# {filename}")
        
        mock_confluence.get_page_child_by_type.return_value = {'results': []}
        
        file_map, dir_structure = sync_tool._traverse_directory()
        operations = sync_tool._build_operations(file_map, dir_structure)
        
        creates = [op for op in operations if op.operation == OperationType.CREATE and op.path.suffix == '.md']
        if len(creates) >= 2:
            # Check that operations are sorted
            paths = [str(op.path) for op in creates]
            assert paths == sorted(paths)
    
    def test_hierarchy_preservation(self, sync_tool, temp_dir, mock_confluence):
        """Test that directory hierarchy is preserved in page structure."""
        # Create nested structure
        level1 = temp_dir / "level1"
        level2 = level1 / "level2"
        level2.mkdir(parents=True)
        
        (level1 / "file1.md").write_text("# File 1")
        (level2 / "file2.md").write_text("# File 2")
        
        # Track created pages with their paths
        created_pages_tracker = {}
        page_counter = 0
        
        def get_page_side_effect(page_id, *args, **kwargs):
            if page_id == sync_tool.root_page_id:
                return {
                    'id': sync_tool.root_page_id,
                    'title': 'Root Page',
                    'space': {'key': 'TEST'},
                    'version': {'number': 1}
                }
            # Return page info for created pages
            return {
                'id': page_id,
                'title': 'Page',
                'space': {'key': 'TEST'},
                'version': {'number': 1}
            }
        
        def create_page_side_effect(*args, **kwargs):
            nonlocal page_counter
            page_id = f"page-{page_counter}"
            page_counter += 1
            parent_id = kwargs.get('parent_id')
            title = kwargs.get('title')
            # Store with a key based on title for now
            created_pages_tracker[title] = page_id
            return {'id': page_id}
        
        mock_confluence.get_page_child_by_type.return_value = {'results': []}
        mock_confluence.get_page_by_id.side_effect = get_page_side_effect
        mock_confluence.create_page.side_effect = create_page_side_effect
        
        file_map, dir_structure = sync_tool._traverse_directory()
        operations = sync_tool._build_operations(file_map, dir_structure)
        
        # Execute operations
        sync_tool._execute_operations(operations)
        
        # Verify that create_page was called
        calls = mock_confluence.create_page.call_args_list
        # level1 dir (has subdirectory), file1, file2 (level2 is single-file so skipped)
        assert len(calls) >= 3, f"Expected at least 3 pages (level1 dir, file1, file2), got {len(calls)}"
        
        # Verify directory pages were created first
        # level1 should be a directory (empty content), level2 should be skipped (single-file)
        dir_calls = [c for c in calls if not c.kwargs.get('body') or c.kwargs.get('body') == '']
        file_calls = [c for c in calls if c.kwargs.get('body') and c.kwargs.get('body') != '']
        
        assert len(dir_calls) >= 1, "Should have at least 1 directory page (level1)"
        assert len(file_calls) >= 2, "Should have at least 2 file pages (file1, file2)"
        
        # Verify files have content
        for call in file_calls:
            body = call.kwargs.get('body', '')
            assert len(body) > 0, f"File page {call.kwargs.get('title')} should have content"
        
        # Verify level2 directory page was NOT created (it's a single-file directory)
        level2_dir_calls = [c for c in calls if c.kwargs.get('title') == 'level2' and not c.kwargs.get('body')]
        assert len(level2_dir_calls) == 0, "level2 is a single-file directory, so its directory page should not be created"
    
    def test_parent_resolution_warning_logging(self, sync_tool, temp_dir, mock_confluence, caplog):
        """Test that detailed warnings are logged when parent resolution fails."""
        # Create a structure where parent resolution might fail
        subdir = temp_dir / "parent"
        subdir.mkdir()
        (subdir / "file.md").write_text("# File")
        
        # Mock to return empty results, simulating a scenario where parent isn't found
        mock_confluence.get_page_child_by_type.return_value = {'results': []}
        
        def get_page_side_effect(page_id, *args, **kwargs):
            if page_id == sync_tool.root_page_id:
                return {
                    'id': sync_tool.root_page_id,
                    'title': 'Root Page',
                    'space': {'key': 'TEST'},
                    'version': {'number': 1}
                }
            return {
                'id': page_id,
                'title': 'Page',
                'space': {'key': 'TEST'},
                'version': {'number': 1}
            }
        
        mock_confluence.get_page_by_id.side_effect = get_page_side_effect
        mock_confluence.create_page.return_value = {'id': 'new-page-id'}
        
        file_map, dir_structure = sync_tool._traverse_directory()
        operations = sync_tool._build_operations(file_map, dir_structure)
        
        # Execute operations with logging capture
        with caplog.at_level("WARNING"):
            sync_tool._execute_operations(operations)
        
        # Check that warnings are logged if parent resolution fails
        # (Note: In this test, parent should be found, but we verify the warning format exists)
        warning_messages = [record.message for record in caplog.records if record.levelname == "WARNING"]
        
        # If any warnings about parent resolution were logged, verify they contain expected details
        parent_warnings = [msg for msg in warning_messages if "Parent resolution" in msg]
        if parent_warnings:
            # Verify warning contains expected diagnostic information
            assert any("returned root page ID" in msg for msg in parent_warnings)
            assert any("Created pages keys" in msg or "created pages" in msg.lower() for msg in parent_warnings)
    
    def test_parent_resolution_successful_hierarchy(self, sync_tool, temp_dir, mock_confluence):
        """Test that parent resolution successfully creates nested hierarchy when keys match."""
        # Create a structure with a directory that has multiple files (so it's not optimized away)
        parent_dir = temp_dir / "parentdir"
        parent_dir.mkdir()
        (parent_dir / "file1.md").write_text("# File 1")
        (parent_dir / "file2.md").write_text("# File 2")
        
        created_pages_tracker = {}
        page_counter = 0
        
        def get_page_side_effect(page_id, *args, **kwargs):
            if page_id == sync_tool.root_page_id:
                return {
                    'id': sync_tool.root_page_id,
                    'title': 'Root Page',
                    'space': {'key': 'TEST'},
                    'version': {'number': 1}
                }
            # Return page info for created pages
            return {
                'id': page_id,
                'title': 'Page',
                'space': {'key': 'TEST'},
                'version': {'number': 1}
            }
        
        def create_page_side_effect(*args, **kwargs):
            nonlocal page_counter
            page_id = f"page-{page_counter}"
            page_counter += 1
            parent_id = kwargs.get('parent_id')
            title = kwargs.get('title')
            created_pages_tracker[title] = {'id': page_id, 'parent_id': parent_id}
            return {'id': page_id}
        
        mock_confluence.get_page_child_by_type.return_value = {'results': []}
        mock_confluence.get_page_by_id.side_effect = get_page_side_effect
        mock_confluence.create_page.side_effect = create_page_side_effect
        
        file_map, dir_structure = sync_tool._traverse_directory()
        operations = sync_tool._build_operations(file_map, dir_structure)
        
        # Execute operations
        sync_tool._execute_operations(operations)
        
        # Verify that pages were created
        calls = mock_confluence.create_page.call_args_list
        assert len(calls) >= 3, "Should create directory page and 2 file pages"
        
        # Verify directory page was created under root
        dir_calls = [c for c in calls if not c.kwargs.get('body') or c.kwargs.get('body') == '']
        assert len(dir_calls) >= 1, "Should create directory page"
        
        # Verify file pages were created
        file_calls = [c for c in calls if c.kwargs.get('body') and c.kwargs.get('body') != '']
        assert len(file_calls) >= 2, "Should create 2 file pages"
    
    def test_nested_hierarchy_bug_fix(self, sync_tool, temp_dir, mock_confluence):
        """
        Test that verifies the bug fix: pages should be created in nested hierarchy, not flat.
        This test specifically checks that parent_id is correctly resolved for nested structures.
        """
        # Create a deeply nested structure: root/parent/child/grandchild/file.md
        parent_dir = temp_dir / "parent"
        child_dir = parent_dir / "child"
        grandchild_dir = child_dir / "grandchild"
        grandchild_dir.mkdir(parents=True)
        
        (parent_dir / "parent-file.md").write_text("# Parent File")
        (child_dir / "child-file.md").write_text("# Child File")
        (grandchild_dir / "grandchild-file.md").write_text("# Grandchild File")
        
        # Track created pages with their parent relationships
        created_pages = {}  # path -> page_id
        page_id_to_parent = {}  # page_id -> parent_id
        page_counter = 0
        
        def get_page_side_effect(page_id, *args, **kwargs):
            if page_id == sync_tool.root_page_id:
                return {
                    'id': sync_tool.root_page_id,
                    'title': 'Root Page',
                    'space': {'key': 'TEST'},
                    'version': {'number': 1}
                }
            # Return page info for created pages
            return {
                'id': page_id,
                'title': page_id_to_parent.get(page_id, {}).get('title', 'Page'),
                'space': {'key': 'TEST'},
                'version': {'number': 1},
                'ancestors': [{'id': page_id_to_parent.get(page_id, {}).get('parent_id', sync_tool.root_page_id)}]
            }
        
        def create_page_side_effect(*args, **kwargs):
            nonlocal page_counter
            page_id = f"page-{page_counter}"
            page_counter += 1
            parent_id = kwargs.get('parent_id')
            title = kwargs.get('title')
            
            # Store the parent relationship
            page_id_to_parent[page_id] = {
                'parent_id': parent_id,
                'title': title
            }
            
            return {'id': page_id}
        
        mock_confluence.get_page_child_by_type.return_value = {'results': []}
        mock_confluence.get_page_by_id.side_effect = get_page_side_effect
        mock_confluence.create_page.side_effect = create_page_side_effect
        
        file_map, dir_structure = sync_tool._traverse_directory()
        operations = sync_tool._build_operations(file_map, dir_structure)
        
        # Execute operations
        sync_tool._execute_operations(operations)
        
        # Verify that pages were created
        calls = mock_confluence.create_page.call_args_list
        # Note: grandchild directory is a single-file directory, so it won't create a directory page
        # Expected: 2 dirs (parent, child) + 3 files = 5 pages total
        assert len(calls) >= 5, f"Expected at least 5 pages (2 dirs + 3 files, grandchild dir is optimized away), got {len(calls)}"
        
        # Extract parent relationships from calls
        page_relationships = {}
        for call in calls:
            title = call.kwargs.get('title', '')
            parent_id = call.kwargs.get('parent_id', '')
            page_relationships[title] = parent_id
        
        # Find directory pages (empty content)
        dir_calls = [c for c in calls if not c.kwargs.get('body') or c.kwargs.get('body') == '']
        file_calls = [c for c in calls if c.kwargs.get('body') and c.kwargs.get('body') != '']
        
        # Should have 2 directory pages (parent and child, grandchild is optimized away)
        assert len(dir_calls) >= 2, f"Expected at least 2 directory pages (parent, child), got {len(dir_calls)}"
        assert len(file_calls) >= 3, f"Expected at least 3 file pages, got {len(file_calls)}"
        
        # Verify hierarchy: parent directory should be under root
        parent_dir_page = None
        child_dir_page = None
        
        for call in dir_calls:
            title = call.kwargs.get('title', '').lower()
            if title == 'parent':
                parent_dir_page = call
            elif title == 'child':
                child_dir_page = call
        
        # Verify parent directory is under root
        assert parent_dir_page is not None, "Parent directory page should be created"
        parent_dir_parent = parent_dir_page.kwargs.get('parent_id')
        assert parent_dir_parent == sync_tool.root_page_id, \
            f"Parent directory should be under root ({sync_tool.root_page_id}), got {parent_dir_parent}"
        
        # Verify child directory is under parent directory (NOT root!)
        assert child_dir_page is not None, "Child directory page should be created"
        child_dir_parent = child_dir_page.kwargs.get('parent_id')
        # CRITICAL: child directory should be under parent directory, NOT root
        # This is the bug we're fixing - it should find the parent directory that was just created
        parent_dir_page_id = None
        for call in dir_calls:
            if call.kwargs.get('title', '').lower() == 'parent':
                # Get the page ID from the mock return value
                # Since we're using side_effect, we need to track it differently
                # Let's check the created_pages tracking
                pass
        
        # The child directory should NOT be under root - this is the bug!
        assert child_dir_parent != sync_tool.root_page_id, \
            f"BUG: Child directory is under root ({sync_tool.root_page_id}) instead of parent directory! " \
            f"This indicates the parent resolution bug is NOT fixed. " \
            f"Child dir parent_id: {child_dir_parent}"
        
        # Verify files are under their respective directories
        for call in file_calls:
            title = call.kwargs.get('title', '')
            parent_id = call.kwargs.get('parent_id')
            assert parent_id is not None, f"File '{title}' should have a parent_id"
            assert parent_id != '', f"File '{title}' parent_id should not be empty"
            
            if 'parent-file' in title.lower():
                # parent-file should be under parent directory, not root
                assert parent_id != sync_tool.root_page_id, \
                    f"BUG: File '{title}' is under root instead of parent directory! " \
                    f"This indicates the bug is not fixed. parent_id: {parent_id}"
            elif 'child-file' in title.lower():
                # child-file should be under child directory
                # It should NOT be under root
                assert parent_id != sync_tool.root_page_id, \
                    f"BUG: File '{title}' is under root instead of child directory! " \
                    f"This indicates the bug is not fixed. parent_id: {parent_id}"
            elif 'grandchild-file' in title.lower():
                # grandchild-file should be under child directory (since grandchild dir is optimized away)
                assert parent_id != sync_tool.root_page_id, \
                    f"BUG: File '{title}' is under root instead of child directory! " \
                    f"This indicates the bug is not fixed. parent_id: {parent_id}"
    
    def test_nested_hierarchy_with_existing_pages(self, sync_tool, temp_dir, mock_confluence):
        """
        Test that verifies parent resolution works when existing pages are present.
        This simulates a scenario where some pages already exist in Confluence.
        """
        # Create nested structure
        parent_dir = temp_dir / "existing-parent"
        child_dir = parent_dir / "existing-child"
        child_dir.mkdir(parents=True)
        
        (parent_dir / "parent-file.md").write_text("# Parent File")
        (child_dir / "child-file.md").write_text("# Child File")
        
        # Simulate existing pages in Confluence
        existing_parent_page = {
            'id': 'existing-parent-123',
            'title': 'existing parent',  # Sanitized version of "existing-parent"
            'version': {'number': 1},
            'parent_id': sync_tool.root_page_id
        }
        
        existing_child_page = {
            'id': 'existing-child-456',
            'title': 'existing child',
            'version': {'number': 1},
            'parent_id': 'existing-parent-123'
        }
        
        def get_page_child_by_type_side_effect(page_id, *args, **kwargs):
            """Simulate existing pages in Confluence."""
            if page_id == sync_tool.root_page_id:
                return {
                    'results': [existing_parent_page]
                }
            elif page_id == 'existing-parent-123':
                return {
                    'results': [existing_child_page]
                }
            return {'results': []}
        
        def get_page_by_id_side_effect(page_id, *args, **kwargs):
            if page_id == sync_tool.root_page_id:
                return {
                    'id': sync_tool.root_page_id,
                    'title': 'Root Page',
                    'space': {'key': 'TEST'},
                    'version': {'number': 1}
                }
            elif page_id == 'existing-parent-123':
                return {
                    'id': 'existing-parent-123',
                    'title': 'existing parent',
                    'space': {'key': 'TEST'},
                    'version': {'number': 1},
                    'ancestors': [{'id': sync_tool.root_page_id}]
                }
            elif page_id == 'existing-child-456':
                return {
                    'id': 'existing-child-456',
                    'title': 'existing child',
                    'space': {'key': 'TEST'},
                    'version': {'number': 1},
                    'ancestors': [{'id': sync_tool.root_page_id}, {'id': 'existing-parent-123'}]
                }
            return {
                'id': page_id,
                'title': 'Page',
                'space': {'key': 'TEST'},
                'version': {'number': 1}
            }
        
        page_counter = 1000  # Start from high number to avoid conflicts
        
        def create_page_side_effect(*args, **kwargs):
            nonlocal page_counter
            page_id = f"new-page-{page_counter}"
            page_counter += 1
            return {'id': page_id}
        
        mock_confluence.get_page_child_by_type.side_effect = get_page_child_by_type_side_effect
        mock_confluence.get_page_by_id.side_effect = get_page_by_id_side_effect
        mock_confluence.create_page.side_effect = create_page_side_effect
        
        file_map, dir_structure = sync_tool._traverse_directory()
        operations = sync_tool._build_operations(file_map, dir_structure)
        
        # Execute operations - mock input to avoid stdin issues
        with patch('builtins.input', return_value='yes'):
            sync_tool._execute_operations(operations)
        
        # Verify that create_page was called for new files
        calls = mock_confluence.create_page.call_args_list
        
        # Should create files (parent-file and child-file)
        # The directories might already exist, so we might not create directory pages
        file_calls = [c for c in calls if c.kwargs.get('body') and c.kwargs.get('body') != '']
        assert len(file_calls) >= 2, f"Expected at least 2 file pages, got {len(file_calls)}"
        
        # Verify that files have correct parent_id
        # parent-file should be under existing-parent-123
        # child-file should be under existing-child-456
        for call in file_calls:
            title = call.kwargs.get('title', '')
            parent_id = call.kwargs.get('parent_id')
            assert parent_id is not None, f"File '{title}' should have a parent_id"
            
            if 'parent-file' in title.lower():
                # Should be under existing parent directory
                assert parent_id == 'existing-parent-123', \
                    f"parent-file should be under existing-parent-123, got {parent_id}"
            elif 'child-file' in title.lower():
                # Should be under existing child directory
                assert parent_id == 'existing-child-456', \
                    f"child-file should be under existing-child-456, got {parent_id}"


# ============================================================================
# Logging Tests
# ============================================================================

class TestLogging:
    """Tests for logging functionality."""
    
    def test_file_logging_creates_file(self, temp_dir):
        """Test that file logging creates a log file."""
        from confluence_sync import setup_logging
        import logging
        
        log_file = temp_dir / "test.log"
        setup_logging(log_file=str(log_file), log_level=logging.INFO)
        
        logger = logging.getLogger(__name__)
        logger.info("Test log message")
        
        # Force handlers to flush
        for handler in logging.getLogger().handlers:
            handler.flush()
            if hasattr(handler, 'close'):
                handler.close()
        
        assert log_file.exists(), "Log file should be created"
        log_content = log_file.read_text(encoding='utf-8')
        assert "Test log message" in log_content, "Log file should contain the log message"
    
    def test_file_logging_creates_directory(self, temp_dir):
        """Test that file logging creates parent directory if it doesn't exist."""
        from confluence_sync import setup_logging
        import logging
        
        log_file = temp_dir / "subdir" / "test.log"
        setup_logging(log_file=str(log_file), log_level=logging.INFO)
        
        logger = logging.getLogger(__name__)
        logger.info("Test message")
        
        # Force handlers to flush
        for handler in logging.getLogger().handlers:
            handler.flush()
            if hasattr(handler, 'close'):
                handler.close()
        
        assert log_file.exists(), "Log file should be created even if parent directory doesn't exist"
        assert (temp_dir / "subdir").exists(), "Parent directory should be created"
    
    def test_file_logging_handles_failure_gracefully(self, temp_dir, caplog):
        """Test that file logging failure doesn't crash the program."""
        from confluence_sync import setup_logging
        import logging
        
        # Close any existing handlers first
        for handler in logging.getLogger().handlers[:]:
            handler.close()
            logging.getLogger().removeHandler(handler)
        
        # Try to log to a path that would fail (e.g., invalid characters on Windows)
        # On Windows, try a path with invalid characters
        import platform
        if platform.system() == 'Windows':
            # Try a path with invalid characters (like < or >)
            invalid_path = temp_dir / "test<invalid>.log"
        else:
            # On Unix, try a path in a non-writable location
            invalid_path = Path("/root/test.log")  # Usually requires root access
        
        # This should not raise an exception
        with caplog.at_level(logging.WARNING):
            try:
                setup_logging(log_file=str(invalid_path), log_level=logging.INFO)
            except Exception:
                # If it raises, that's also acceptable - the important thing is it doesn't crash the program
                pass
        
        # Should still be able to log to console
        logger = logging.getLogger(__name__)
        logger.info("Console log message")
        
        # Clean up handlers
        for handler in logging.getLogger().handlers[:]:
            handler.close()
            logging.getLogger().removeHandler(handler)
        
        # The test passes if no exception was raised and console logging still works
        # (The warning might not be captured if logging setup fails before handlers are added)
        assert True  # Test passes if we get here without crashing
    
    def test_logging_without_file(self):
        """Test that logging works without a file (console only)."""
        from confluence_sync import setup_logging
        import logging
        
        # Clear existing handlers
        logging.getLogger().handlers.clear()
        
        setup_logging(log_file=None, log_level=logging.INFO)
        
        logger = logging.getLogger(__name__)
        logger.info("Console only message")
        
        # Should have at least one handler (console)
        handlers = logging.getLogger().handlers
        assert len(handlers) >= 1, "Should have at least console handler"
        assert any(isinstance(h, logging.StreamHandler) for h in handlers), \
            "Should have a StreamHandler for console logging"


# ============================================================================
# Preview and Confirmation Tests
# ============================================================================

class TestPreview:
    """Tests for preview functionality."""
    
    def test_preview_operations(self, sync_tool, capsys):
        """Test that preview displays operations correctly."""
        operations = [
            PageOperation(OperationType.CREATE, "New Page", Path("new.md")),
            PageOperation(OperationType.UPDATE, "Updated Page", Path("updated.md"), page_id="123"),
            PageOperation(OperationType.DELETE, "Deleted Page", Path("deleted.md"), page_id="456")
        ]
        
        sync_tool._preview_operations(operations)
        
        captured = capsys.readouterr()
        assert "CREATE" in captured.out or "create" in captured.out.lower()
        assert "UPDATE" in captured.out or "update" in captured.out.lower()
        assert "DELETE" in captured.out or "delete" in captured.out.lower()
    
    def test_preview_no_changes(self, sync_tool, capsys):
        """Test preview when there are no changes."""
        operations = []
        
        sync_tool._preview_operations(operations)
        
        captured = capsys.readouterr()
        assert "No changes" in captured.out or "in sync" in captured.out.lower()


# ============================================================================
# Created Pages List Tests
# ============================================================================

class TestCreatedPagesList:
    """Tests for created pages list functionality."""
    
    def test_save_created_pages_list_creates_file(self, sync_tool, mock_confluence, temp_dir):
        """Test that _save_created_pages_list creates a JSON file."""
        # Set up sync state with created pages
        sync_tool.sync_state.created_pages = ['11111', '22222', '33333']
        
        # Mock get_page_by_id to return page details
        def get_page_side_effect(page_id):
            return {
                'id': page_id,
                'title': f'Page {page_id}',
                'space': {'key': 'TEST'},
                'version': {'number': 1}
            }
        
        mock_confluence.get_page_by_id.side_effect = get_page_side_effect
        
        # Change to temp directory to avoid cluttering test directory
        original_cwd = os.getcwd()
        try:
            os.chdir(temp_dir)
            sync_tool._save_created_pages_list()
            
            # Check that a JSON file was created
            json_files = list(Path(temp_dir).glob('created_pages_*.json'))
            assert len(json_files) == 1, f"Expected 1 JSON file, found {len(json_files)}"
            
            # Verify file contents
            with open(json_files[0], 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            assert 'timestamp' in data
            assert data['root_page_id'] == sync_tool.root_page_id
            assert data['root_page_title'] == sync_tool.root_page_title
            assert len(data['created_pages']) == 3
            assert data['created_pages'][0]['page_id'] == '11111'
            assert data['created_pages'][1]['page_id'] == '22222'
            assert data['created_pages'][2]['page_id'] == '33333'
        finally:
            os.chdir(original_cwd)
    
    def test_save_created_pages_list_json_structure(self, sync_tool, mock_confluence, temp_dir):
        """Test that the JSON file has the correct structure."""
        sync_tool.sync_state.created_pages = ['12345']
        
        mock_confluence.get_page_by_id.return_value = {
            'id': '12345',
            'title': 'Test Page',
            'space': {'key': 'TESTSPACE'},
            'version': {'number': 2}
        }
        
        original_cwd = os.getcwd()
        try:
            os.chdir(temp_dir)
            sync_tool._save_created_pages_list()
            
            json_files = list(Path(temp_dir).glob('created_pages_*.json'))
            with open(json_files[0], 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # Verify all required fields
            assert 'timestamp' in data
            assert 'root_page_id' in data
            assert 'root_page_title' in data
            assert 'directory_path' in data
            assert 'created_pages' in data
            
            # Verify page structure
            assert len(data['created_pages']) == 1
            page = data['created_pages'][0]
            assert 'page_id' in page
            assert 'title' in page
            assert 'space' in page
            assert 'version' in page
            
            assert page['page_id'] == '12345'
            assert page['title'] == 'Test Page'
            assert page['space'] == 'TESTSPACE'
            assert page['version'] == 2
        finally:
            os.chdir(original_cwd)
    
    def test_save_created_pages_list_handles_missing_page_details(self, sync_tool, mock_confluence, temp_dir):
        """Test that saving handles cases where page details can't be retrieved."""
        sync_tool.sync_state.created_pages = ['11111', '22222']
        
        # First page succeeds, second fails
        def get_page_side_effect(page_id):
            if page_id == '11111':
                return {
                    'id': '11111',
                    'title': 'Valid Page',
                    'space': {'key': 'TEST'},
                    'version': {'number': 1}
                }
            else:
                raise Exception("Page not found")
        
        mock_confluence.get_page_by_id.side_effect = get_page_side_effect
        
        original_cwd = os.getcwd()
        try:
            os.chdir(temp_dir)
            sync_tool._save_created_pages_list()
            
            json_files = list(Path(temp_dir).glob('created_pages_*.json'))
            with open(json_files[0], 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # Should still save both pages
            assert len(data['created_pages']) == 2
            assert data['created_pages'][0]['page_id'] == '11111'
            assert data['created_pages'][0]['title'] == 'Valid Page'
            assert data['created_pages'][1]['page_id'] == '22222'
            assert data['created_pages'][1]['title'] == 'Unknown'  # Default when retrieval fails
        finally:
            os.chdir(original_cwd)
    
    def test_save_created_pages_list_handles_errors_gracefully(self, sync_tool, mock_confluence, temp_dir, caplog):
        """Test that errors during save don't crash the program."""
        sync_tool.sync_state.created_pages = ['11111']
        
        # Make file write fail by using invalid path
        with patch('builtins.open', side_effect=PermissionError("Access denied")):
            sync_tool._save_created_pages_list()
        
        # Should log warning but not raise exception
        assert any("Could not save created pages list" in record.message for record in caplog.records)
    
    def test_save_created_pages_list_with_empty_list(self, sync_tool, mock_confluence, temp_dir):
        """Test that save creates a file even with empty list (but sync() doesn't call it)."""
        sync_tool.sync_state.created_pages = []
        
        original_cwd = os.getcwd()
        try:
            os.chdir(temp_dir)
            sync_tool._save_created_pages_list()
            
            # Method creates file even with empty list, but sync() won't call it
            json_files = list(Path(temp_dir).glob('created_pages_*.json'))
            if len(json_files) > 0:
                # If file was created, verify it has empty list
                with open(json_files[0], 'r', encoding='utf-8') as f:
                    data = json.load(f)
                assert len(data['created_pages']) == 0
        finally:
            os.chdir(original_cwd)
    
    def test_sync_saves_created_pages_list(self, sync_tool, temp_dir, mock_confluence):
        """Test that sync() automatically saves the list after successful completion."""
        (temp_dir / "test.md").write_text("# Test\n\nContent")
        
        mock_confluence.get_page_child_by_type.return_value = {'results': []}
        mock_confluence.create_page.return_value = {'id': '99999'}
        mock_confluence.get_page_by_id.return_value = {
            'id': '12345',
            'title': 'Root Page',
            'space': {'key': 'TEST'},
            'version': {'number': 1}
        }
        mock_confluence.get_page_labels.return_value = {'results': []}
        
        original_cwd = os.getcwd()
        try:
            os.chdir(temp_dir)
            
            # Mock input to confirm operations
            with patch('builtins.input', return_value='yes'):
                sync_tool.sync(dry_run=False)
            
            # Verify JSON file was created
            json_files = list(Path(temp_dir).glob('created_pages_*.json'))
            assert len(json_files) >= 1, "Expected at least one JSON file to be created"
            
            # Verify file contains created pages
            with open(json_files[0], 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            assert len(data['created_pages']) > 0
            assert data['root_page_id'] == sync_tool.root_page_id
        finally:
            os.chdir(original_cwd)
    
    def test_sync_does_not_save_list_in_dry_run(self, sync_tool, temp_dir, mock_confluence):
        """Test that sync() does not save the list in dry-run mode."""
        (temp_dir / "test.md").write_text("# Test\n\nContent")
        
        mock_confluence.get_page_child_by_type.return_value = {'results': []}
        mock_confluence.get_page_by_id.return_value = {
            'id': '12345',
            'title': 'Root Page',
            'space': {'key': 'TEST'},
            'version': {'number': 1}
        }
        
        original_cwd = os.getcwd()
        try:
            os.chdir(temp_dir)
            sync_tool.sync(dry_run=True)
            
            # Should not create JSON file in dry-run
            json_files = list(Path(temp_dir).glob('created_pages_*.json'))
            assert len(json_files) == 0, "Should not create JSON file in dry-run mode"
        finally:
            os.chdir(original_cwd)


# ============================================================================
# Run Tests
# ============================================================================

if __name__ == '__main__':
    pytest.main([__file__, '-v', '--tb=short'])
