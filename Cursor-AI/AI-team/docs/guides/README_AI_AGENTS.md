# AI-Powered Agent Team

The AI agent team has been enhanced to use **true AI code generation** instead of templates. Agents now use LLM APIs (OpenAI, Anthropic) to generate code dynamically based on requirements and tasks.

## Features

- **AI-Powered Code Generation**: Agents use LLM APIs to generate code based on task descriptions and requirements
- **Automatic Fallback**: If AI is unavailable, agents fall back to template-based generation
- **Multi-Provider Support**: Supports both OpenAI and Anthropic APIs
- **Intelligent Code Generation**: AI generates complete, production-ready code with proper structure
- **Test Generation**: Automatically generates test files for new code

## Setup

### 1. Install Required Packages

```bash
python setup_ai_agents.py
```

This installs:
- `openai` - For OpenAI API (GPT-4, GPT-3.5)
- `anthropic` - For Anthropic API (Claude)

### 2. Configure API Keys

You need an API key from either OpenAI or Anthropic. The agents will automatically use whichever is available.

#### Option A: Environment Variables (Recommended)

**Windows (PowerShell):**
```powershell
$env:OPENAI_API_KEY="your-openai-api-key-here"
# OR
$env:ANTHROPIC_API_KEY="your-anthropic-api-key-here"
```

**Windows (Command Prompt):**
```cmd
set OPENAI_API_KEY=your-openai-api-key-here
set ANTHROPIC_API_KEY=your-anthropic-api-key-here
```

**Linux/Mac:**
```bash
export OPENAI_API_KEY="your-openai-api-key-here"
export ANTHROPIC_API_KEY="your-anthropic-api-key-here"
```

#### Option B: .env File

Create a `.env` file in the project root:

```
OPENAI_API_KEY=your-openai-api-key-here
ANTHROPIC_API_KEY=your-anthropic-api-key-here
```

Then install `python-dotenv` and load it:
```bash
pip install python-dotenv
```

### 3. Get API Keys

- **OpenAI**: Get your API key from https://platform.openai.com/api-keys
- **Anthropic**: Get your API key from https://console.anthropic.com/

## How It Works

### AI Code Generation Flow

1. **Agent receives task** from coordinator
2. **Agent loads requirements** from `requirements.md`
3. **Agent checks for AI client** (looks for API keys)
4. **If AI available**:
   - Builds prompt from task description and requirements
   - Calls LLM API to generate code
   - Writes generated code to appropriate file
   - Generates test file
5. **If AI unavailable**:
   - Falls back to template-based generation (original behavior)

### Example: AI Generation

When an agent receives a task like "Implement ebook parsing", it:

1. Builds a prompt:
   ```
   Task: Implement ebook parsing
   Description: Create a service to parse EPUB and MOBI files
   
   Requirements:
   - Support EPUB format
   - Support MOBI format
   - Extract text content
   ...
   ```

2. Sends to LLM (e.g., GPT-4):
   ```python
   ai_client.generate_code(
       prompt="Implement ebook parsing...",
       context="Project: React Native mobile app...",
       language="javascript"
   )
   ```

3. Receives generated code:
   ```javascript
   import * as FileSystem from 'expo-file-system';
   
   class EbookParser {
     async parseEpub(fileUri) {
       // Complete implementation generated by AI
     }
   }
   ```

4. Writes to file: `src/services/ebook_parser.js`

## Configuration

### Provider Selection

The agents automatically try providers in this order:
1. OpenAI (if `OPENAI_API_KEY` is set)
2. Anthropic (if `ANTHROPIC_API_KEY` is set)

You can also specify a provider explicitly in the agent initialization (future enhancement).

### Model Selection

Default models:
- **OpenAI**: `gpt-4-turbo-preview` (or `gpt-4`, `gpt-3.5-turbo`)
- **Anthropic**: `claude-3-opus-20240229` (or `claude-3-sonnet-20240229`)

Models can be customized in `ai_client.py`.

## Benefits

### AI-Powered Generation
- ✅ **Dynamic Code**: Code is generated based on actual requirements, not templates
- ✅ **Context-Aware**: AI understands project structure and requirements
- ✅ **Complete Solutions**: Generates full implementations, not just stubs
- ✅ **Best Practices**: AI follows coding best practices automatically

### Template Fallback
- ✅ **Reliability**: Always works, even without API keys
- ✅ **Speed**: Instant generation (no API calls)
- ✅ **Predictability**: Consistent output

## Troubleshooting

### "AI client not available"

**Cause**: No API key found in environment variables.

**Solution**: 
1. Set `OPENAI_API_KEY` or `ANTHROPIC_API_KEY` environment variable
2. Restart the agent team

### "Failed to generate code"

**Cause**: API call failed (network, rate limit, invalid key).

**Solution**:
1. Check your API key is valid
2. Check your internet connection
3. Check API rate limits
4. Agents will automatically fall back to templates

### "Module not found: openai"

**Cause**: Required packages not installed.

**Solution**:
```bash
python setup_ai_agents.py
```

## Cost Considerations

- **OpenAI**: Pay-per-use based on tokens (see https://openai.com/pricing)
- **Anthropic**: Pay-per-use based on tokens (see https://www.anthropic.com/pricing)

**Tips**:
- Use GPT-3.5-turbo for faster/cheaper generation
- Use GPT-4 or Claude Opus for complex tasks
- Monitor usage in your API dashboard

## Security

- **Never commit API keys** to version control
- Use environment variables or secure secret management
- Add `.env` to `.gitignore`
- Rotate API keys regularly

## Future Enhancements

- [ ] Support for local LLMs (Ollama, LM Studio)
- [ ] Caching generated code to reduce API calls
- [ ] Multi-model ensemble (try multiple models, pick best)
- [ ] Code review and refinement loops
- [ ] Integration with Cursor's internal AI (if API becomes available)

